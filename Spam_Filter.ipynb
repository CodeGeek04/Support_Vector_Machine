{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9bb9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import preprocessing , svm , model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1e93bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 msg label  label_no  NNP  IN  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   ham         0    3   2   \n",
      "1                      Ok lar... Joking wif u oni...   ham         0    2   0   \n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam         1    6   1   \n",
      "3  U dun say so early hor... U c already then say...   ham         0    1   0   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   ham         0    1   1   \n",
      "\n",
      "   JJ  NN  ,  RB  :  ...  MD  PRP$  JJR  JJS  UH  RP  WP  WDT  #  ''  \n",
      "0   3   7  1   3  2  ...   0     0    0    0   0   0   0    0  0   0  \n",
      "1   1   2  0   0  2  ...   0     0    0    0   0   0   0    0  0   0  \n",
      "2   4   7  0   0  0  ...   0     0    0    0   0   0   0    0  0   0  \n",
      "3   2   1  0   3  2  ...   0     0    0    0   0   0   0    0  0   0  \n",
      "4   0   0  1   3  0  ...   0     0    0    0   0   0   0    0  0   0  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "tok_dict={}\n",
    "\n",
    "lst=['NNP', 'IN', 'JJ', 'NN', ',', 'RB', ':', 'EX', 'VBD', 'WRB', 'CD', 'DT', 'TO', 'VB', '.',\n",
    "     '(', ')', 'CC', 'POS', 'VBP', 'NNS', 'PRP', 'VBZ', 'VBG', 'VBN', 'MD', 'PRP$', 'JJR', 'JJS', 'UH', 'RP', 'WP', 'WDT', '#', \"''\"]\n",
    "\n",
    "pd_dict={'msg':[],'label':[],'label_no':[],'NNP':[], 'IN':[], 'JJ':[], 'NN':[], ',':[], 'RB':[], ':':[], 'EX':[], 'VBD':[], \n",
    "'WRB':[], 'CD':[], 'DT':[], 'TO':[], 'VB':[], '.':[], '(':[], ')':[], 'CC':[],\n",
    "'POS':[], 'VBP':[], 'NNS':[], 'PRP':[], 'VBZ':[], 'VBG':[], 'VBN':[], 'MD':[], \n",
    "'PRP$':[], 'JJR':[], 'JJS':[], 'UH':[], 'RP':[], 'WP':[], 'WDT':[], '#':[], \"''\":[]}\n",
    "\n",
    "with open(\"spam_db.csv\", 'r') as file:\n",
    "  csvreader = csv.reader(file)\n",
    "  j=0\n",
    "  k=0\n",
    "  for row in csvreader:\n",
    "    if j==0:\n",
    "        j=1\n",
    "        continue\n",
    "    pd_dict['msg'].append(row[1])\n",
    "    pd_dict['label'].append(row[0])\n",
    "    if row[0]=='spam':\n",
    "        pd_dict['label_no'].append(1)\n",
    "    else:\n",
    "        pd_dict['label_no'].append(0)\n",
    "    for label in lst:\n",
    "        pd_dict[label].append(0)\n",
    "    text=row[1]\n",
    "    tokens=word_tokenize(text)\n",
    "    tokens_tagged=nltk.pos_tag(tokens)\n",
    "    for i in tokens_tagged:\n",
    "        if i[1] in tok_dict:\n",
    "            tok_dict[i[1]].append(i[0])\n",
    "        else:\n",
    "            tok_dict[i[1]]=[i[0]]\n",
    "        if i[1] in pd_dict:\n",
    "          pd_dict[i[1]][k]+=1\n",
    "    k+=1\n",
    "        \n",
    "tok_dict1={}\n",
    "for i in tok_dict:\n",
    "    tok_dict1[i]=len(tok_dict[i])\n",
    "\n",
    "del_lst=[]\n",
    "for i in tok_dict1:\n",
    "    if tok_dict1[i]<100:\n",
    "        del_lst.append(i)\n",
    "\n",
    "for i in del_lst:\n",
    "    tok_dict1.pop(i)\n",
    "\n",
    "lst=[]\n",
    "for i in tok_dict1:\n",
    "    lst.append(i)\n",
    "\n",
    "df=pd.DataFrame(pd_dict)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35824c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_12760\\3238635716.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X=np.array(df.drop(['msg','label','label_no'],1))\n"
     ]
    }
   ],
   "source": [
    "X=np.array(df.drop(['msg','label','label_no'],1))\n",
    "y=np.array(df['label_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aec84e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713261648745519\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.1)\n",
    "clf=svm.SVC(kernel='poly')\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccce58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''WINNER!! As a valued network customer you have been selected to receivea \n",
    "å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f53b1187",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(text)\n",
    "tokens_tagged=nltk.pos_tag(tokens)\n",
    "x=[]\n",
    "for i in range(35):\n",
    "    x.append(0)\n",
    "pos_dict={'NNP':[0], 'IN':[1], 'JJ':[2], 'NN':[3], ',':[4], 'RB':[5], ':':[6], 'EX':[7], 'VBD':[8], \n",
    "'WRB':[9], 'CD':[10], 'DT':[11], 'TO':[12], 'VB':[13], '.':[14], '(':[15], ')':[16], 'CC':[17],\n",
    "'POS':[18], 'VBP':[19], 'NNS':[20], 'PRP':[21], 'VBZ':[22], 'VBG':[23], 'VBN':[24], 'MD':[25], \n",
    "'PRP$':[26], 'JJR':[27], 'JJS':[28], 'UH':[29], 'RP':[30], 'WP':[31], 'WDT':[32], '#':[33], \"''\":[34]}\n",
    "for i in tokens_tagged:\n",
    "    x[pos_dict[i[1]][0]]+=1\n",
    "x=np.array(x)\n",
    "x=x.reshape(1,-1)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d0066d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM\n"
     ]
    }
   ],
   "source": [
    "pred=clf.predict(x)\n",
    "if pred==0:\n",
    "    print(\"NOT SPAM\")\n",
    "else:\n",
    "    print(\"SPAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e97e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
